{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/susan291-gifs/SussieAssignment/blob/main/Keras_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "G5NG5tVxMG6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 3"
      ],
      "metadata": {
        "id": "T_4M02lWMJMD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS7udfng9yB5",
        "outputId": "5e05250b-b824-4420-960c-a4649cea2bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 2s 63ms/step - loss: 0.6612 - accuracy: 0.5469 - val_loss: 0.6648 - val_accuracy: 0.3750\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6261 - accuracy: 0.5312 - val_loss: 0.6548 - val_accuracy: 0.3750\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6083 - accuracy: 0.5469 - val_loss: 0.6428 - val_accuracy: 0.3750\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5928 - accuracy: 0.5625 - val_loss: 0.6274 - val_accuracy: 0.4375\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5764 - accuracy: 0.5938 - val_loss: 0.5959 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5561 - accuracy: 0.6250 - val_loss: 0.5763 - val_accuracy: 0.5625\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5348 - accuracy: 0.6562 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5130 - accuracy: 0.7344 - val_loss: 0.5164 - val_accuracy: 0.8125\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.8750 - val_loss: 0.4823 - val_accuracy: 0.8750\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.9219 - val_loss: 0.4547 - val_accuracy: 0.8750\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4437 - accuracy: 0.9062 - val_loss: 0.4384 - val_accuracy: 0.8750\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4224 - accuracy: 0.9062 - val_loss: 0.4138 - val_accuracy: 0.8750\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3950 - accuracy: 0.9062 - val_loss: 0.3698 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3680 - accuracy: 0.9375 - val_loss: 0.3367 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.3442 - accuracy: 0.9531 - val_loss: 0.3050 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.3198 - accuracy: 0.9375 - val_loss: 0.2944 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3012 - accuracy: 0.9375 - val_loss: 0.2646 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2731 - accuracy: 0.9531 - val_loss: 0.2294 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2548 - accuracy: 0.9375 - val_loss: 0.2006 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2424 - accuracy: 0.9375 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2212 - accuracy: 0.9531 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2034 - accuracy: 0.9531 - val_loss: 0.1488 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1901 - accuracy: 0.9375 - val_loss: 0.1332 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1741 - accuracy: 0.9375 - val_loss: 0.1278 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1706 - accuracy: 0.9531 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1616 - accuracy: 0.9531 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1481 - accuracy: 0.9375 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.9375 - val_loss: 0.0859 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1377 - accuracy: 0.9531 - val_loss: 0.0831 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1287 - accuracy: 0.9531 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1230 - accuracy: 0.9531 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1236 - accuracy: 0.9531 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1151 - accuracy: 0.9531 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1105 - accuracy: 0.9531 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1075 - accuracy: 0.9375 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1084 - accuracy: 0.9375 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1143 - accuracy: 0.9531 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1051 - accuracy: 0.9375 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0972 - accuracy: 0.9375 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9531 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0907 - accuracy: 0.9531 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0942 - accuracy: 0.9688 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0887 - accuracy: 0.9688 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9688 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0950 - accuracy: 0.9531 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9531 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0905 - accuracy: 0.9688 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0771 - accuracy: 0.9688 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0859 - accuracy: 0.9531 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9531 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.9844 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9688 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0723 - accuracy: 0.9688 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9688 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9688 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0692 - accuracy: 0.9844 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9844 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0668 - accuracy: 0.9844 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0667 - accuracy: 0.9688 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0651 - accuracy: 0.9688 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0679 - accuracy: 0.9844 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0660 - accuracy: 0.9844 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 0.9844 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0617 - accuracy: 0.9844 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0607 - accuracy: 0.9844 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9844 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 0.9844 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0595 - accuracy: 0.9844 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9688 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0566 - accuracy: 0.9844 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0581 - accuracy: 0.9844 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9688 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0682 - accuracy: 0.9688 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9844 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0560 - accuracy: 0.9844 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0554 - accuracy: 0.9688 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9844 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 0.9844 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 0.9844 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 0.9844 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9844 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0511 - accuracy: 0.9844 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9844 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9844 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9844 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0464 - accuracy: 0.9844 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9844 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0422 - accuracy: 0.9844 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9844 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9844 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
            "1/1 - 0s - loss: 0.1982 - accuracy: 0.9000 - 23ms/epoch - 23ms/step\n",
            "Test Accuracy: 0.900\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Iris.csv')\n",
        "\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"].map({\"Iris-versicolor\": 0, \"Iris-virginica\": 1}).values\n",
        "X = df[[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 4"
      ],
      "metadata": {
        "id": "xFxHa0yZMzHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Iris.csv')\n",
        "\n",
        "y = df[\"Species\"]\n",
        "X = df[[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]].values\n",
        "\n",
        "y = y.map({\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}).values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_val = enc.transform(y_val[:, np.newaxis])\n",
        "y_test = enc.transform(y_test[:, np.newaxis])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJP4qIKMMwPB",
        "outputId": "5c1115bb-7430-4552-dbc1-243e4bcb55d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 1.0009 - accuracy: 0.4792 - val_loss: 0.9468 - val_accuracy: 0.7083\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9177 - accuracy: 0.6875 - val_loss: 0.8668 - val_accuracy: 0.7083\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8391 - accuracy: 0.6875 - val_loss: 0.7903 - val_accuracy: 0.7083\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7601 - accuracy: 0.6875 - val_loss: 0.7145 - val_accuracy: 0.7083\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6869 - accuracy: 0.6875 - val_loss: 0.6420 - val_accuracy: 0.7083\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6160 - accuracy: 0.6875 - val_loss: 0.5780 - val_accuracy: 0.7083\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5578 - accuracy: 0.6875 - val_loss: 0.5206 - val_accuracy: 0.7083\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.6979 - val_loss: 0.4757 - val_accuracy: 0.7083\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7500 - val_loss: 0.4404 - val_accuracy: 0.7083\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7708 - val_loss: 0.4126 - val_accuracy: 0.7917\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8958 - val_loss: 0.3895 - val_accuracy: 0.9167\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.9271 - val_loss: 0.3685 - val_accuracy: 0.9167\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.9271 - val_loss: 0.3490 - val_accuracy: 0.9167\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3446 - accuracy: 0.9167 - val_loss: 0.3308 - val_accuracy: 0.9167\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3249 - accuracy: 0.9479 - val_loss: 0.3158 - val_accuracy: 0.9583\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3094 - accuracy: 0.9479 - val_loss: 0.2999 - val_accuracy: 0.9583\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2944 - accuracy: 0.9271 - val_loss: 0.2881 - val_accuracy: 0.9167\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2939 - accuracy: 0.9271 - val_loss: 0.2728 - val_accuracy: 0.9583\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2540 - accuracy: 0.9479 - val_loss: 0.2628 - val_accuracy: 0.9167\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2502 - accuracy: 0.9479 - val_loss: 0.2461 - val_accuracy: 0.9583\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2285 - accuracy: 0.9583 - val_loss: 0.2347 - val_accuracy: 0.9583\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2176 - accuracy: 0.9583 - val_loss: 0.2246 - val_accuracy: 0.9583\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2089 - accuracy: 0.9479 - val_loss: 0.2150 - val_accuracy: 0.9583\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.9583 - val_loss: 0.2093 - val_accuracy: 0.9583\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1882 - accuracy: 0.9583 - val_loss: 0.1978 - val_accuracy: 0.9583\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1799 - accuracy: 0.9375 - val_loss: 0.1936 - val_accuracy: 0.9583\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.9479 - val_loss: 0.1848 - val_accuracy: 0.9583\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1668 - accuracy: 0.9583 - val_loss: 0.1832 - val_accuracy: 0.9167\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.9688 - val_loss: 0.1739 - val_accuracy: 0.9583\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1456 - accuracy: 0.9583 - val_loss: 0.1857 - val_accuracy: 0.9167\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1368 - accuracy: 0.9583 - val_loss: 0.1622 - val_accuracy: 0.9583\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1338 - accuracy: 0.9583 - val_loss: 0.1583 - val_accuracy: 0.9583\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9688 - val_loss: 0.1686 - val_accuracy: 0.9167\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1210 - accuracy: 0.9688 - val_loss: 0.1509 - val_accuracy: 0.9583\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9375 - val_loss: 0.1471 - val_accuracy: 0.9583\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1329 - accuracy: 0.9583 - val_loss: 0.2057 - val_accuracy: 0.9167\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1104 - accuracy: 0.9688 - val_loss: 0.1409 - val_accuracy: 0.9583\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.9688 - val_loss: 0.1384 - val_accuracy: 0.9583\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9583 - val_loss: 0.1415 - val_accuracy: 0.9167\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1014 - accuracy: 0.9583 - val_loss: 0.1431 - val_accuracy: 0.9167\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0996 - accuracy: 0.9583 - val_loss: 0.1388 - val_accuracy: 0.9167\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0953 - accuracy: 0.9583 - val_loss: 0.1316 - val_accuracy: 0.9583\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0965 - accuracy: 0.9688 - val_loss: 0.1389 - val_accuracy: 0.9167\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9583 - val_loss: 0.1273 - val_accuracy: 0.9583\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9583 - val_loss: 0.1367 - val_accuracy: 0.9167\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0881 - accuracy: 0.9583 - val_loss: 0.1276 - val_accuracy: 0.9583\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9583 - val_loss: 0.1301 - val_accuracy: 0.9167\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0924 - accuracy: 0.9688 - val_loss: 0.1496 - val_accuracy: 0.9167\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9583 - val_loss: 0.1199 - val_accuracy: 0.9583\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9583 - val_loss: 0.1483 - val_accuracy: 0.9167\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0851 - accuracy: 0.9583 - val_loss: 0.1293 - val_accuracy: 0.9167\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0776 - accuracy: 0.9583 - val_loss: 0.1303 - val_accuracy: 0.9167\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0834 - accuracy: 0.9583 - val_loss: 0.1200 - val_accuracy: 0.9167\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0749 - accuracy: 0.9688 - val_loss: 0.1435 - val_accuracy: 0.9167\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0743 - accuracy: 0.9583 - val_loss: 0.1189 - val_accuracy: 0.9167\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0729 - accuracy: 0.9583 - val_loss: 0.1336 - val_accuracy: 0.9167\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.0711 - accuracy: 0.9583 - val_loss: 0.1263 - val_accuracy: 0.9167\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0708 - accuracy: 0.9583 - val_loss: 0.1304 - val_accuracy: 0.9167\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0685 - accuracy: 0.9583 - val_loss: 0.1210 - val_accuracy: 0.9167\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0688 - accuracy: 0.9688 - val_loss: 0.1261 - val_accuracy: 0.9167\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0669 - accuracy: 0.9792 - val_loss: 0.1209 - val_accuracy: 0.9167\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9583 - val_loss: 0.1291 - val_accuracy: 0.9167\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0668 - accuracy: 0.9688 - val_loss: 0.1169 - val_accuracy: 0.9167\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0657 - accuracy: 0.9792 - val_loss: 0.1262 - val_accuracy: 0.9167\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0701 - accuracy: 0.9583 - val_loss: 0.1404 - val_accuracy: 0.9167\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0702 - accuracy: 0.9688 - val_loss: 0.1080 - val_accuracy: 0.9583\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0659 - accuracy: 0.9688 - val_loss: 0.1578 - val_accuracy: 0.9167\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 0.9688 - val_loss: 0.1290 - val_accuracy: 0.9167\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0674 - accuracy: 0.9792 - val_loss: 0.1140 - val_accuracy: 0.9167\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0595 - accuracy: 0.9792 - val_loss: 0.1322 - val_accuracy: 0.9167\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.9688 - val_loss: 0.1434 - val_accuracy: 0.9167\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 0.1107 - val_accuracy: 0.9167\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9792 - val_loss: 0.1303 - val_accuracy: 0.9167\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 0.1604 - val_accuracy: 0.9167\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0604 - accuracy: 0.9688 - val_loss: 0.1036 - val_accuracy: 0.9583\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0664 - accuracy: 0.9688 - val_loss: 0.1411 - val_accuracy: 0.9167\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.1111 - val_accuracy: 0.9167\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0579 - accuracy: 0.9792 - val_loss: 0.1189 - val_accuracy: 0.9167\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0721 - accuracy: 0.9583 - val_loss: 0.1554 - val_accuracy: 0.9167\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0566 - accuracy: 0.9688 - val_loss: 0.1061 - val_accuracy: 0.9167\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.1393 - val_accuracy: 0.9167\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0567 - accuracy: 0.9792 - val_loss: 0.1369 - val_accuracy: 0.9167\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 0.9792 - val_loss: 0.1123 - val_accuracy: 0.9167\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0547 - accuracy: 0.9792 - val_loss: 0.1269 - val_accuracy: 0.9167\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0555 - accuracy: 0.9792 - val_loss: 0.1426 - val_accuracy: 0.9167\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0546 - accuracy: 0.9792 - val_loss: 0.1413 - val_accuracy: 0.9167\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 0.9792 - val_loss: 0.1498 - val_accuracy: 0.9167\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0511 - accuracy: 0.9792 - val_loss: 0.1188 - val_accuracy: 0.9167\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0545 - accuracy: 0.9896 - val_loss: 0.1178 - val_accuracy: 0.9167\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9688 - val_loss: 0.1573 - val_accuracy: 0.9167\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9688 - val_loss: 0.1213 - val_accuracy: 0.9167\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.9792 - val_loss: 0.1075 - val_accuracy: 0.9167\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0472 - accuracy: 0.9688 - val_loss: 0.2085 - val_accuracy: 0.9167\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9792 - val_loss: 0.1294 - val_accuracy: 0.9167\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9688 - val_loss: 0.1277 - val_accuracy: 0.9167\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0522 - accuracy: 0.9792 - val_loss: 0.1249 - val_accuracy: 0.9167\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0521 - accuracy: 0.9792 - val_loss: 0.1527 - val_accuracy: 0.9167\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0491 - accuracy: 0.9688 - val_loss: 0.1304 - val_accuracy: 0.9167\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9792 - val_loss: 0.1261 - val_accuracy: 0.9167\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.9792 - val_loss: 0.1552 - val_accuracy: 0.9167\n",
            "1/1 - 0s - loss: 0.0416 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Test Accuracy: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 5"
      ],
      "metadata": {
        "id": "Pv-5FwSkOFLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/train.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]].values\n",
        "y = df[\"SalePrice\"].values\n",
        "\n",
        "y = np.log(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_rmse = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test RMSE: {test_rmse:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFiRPMzWOCzj",
        "outputId": "8b040e6b-9519-4616-db35-c482dce664ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 86.7677 - root_mean_squared_error: 9.3149 - val_loss: 8.3722 - val_root_mean_squared_error: 2.8935\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 2.9848 - root_mean_squared_error: 1.7277 - val_loss: 1.7675 - val_root_mean_squared_error: 1.3295\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 1.3292 - root_mean_squared_error: 1.1529 - val_loss: 0.7363 - val_root_mean_squared_error: 0.8581\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.5451 - root_mean_squared_error: 0.7383 - val_loss: 0.3337 - val_root_mean_squared_error: 0.5776\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2492 - root_mean_squared_error: 0.4992 - val_loss: 0.1886 - val_root_mean_squared_error: 0.4343\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.1264 - root_mean_squared_error: 0.3555 - val_loss: 0.0883 - val_root_mean_squared_error: 0.2971\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0766 - root_mean_squared_error: 0.2768 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2448\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0588 - root_mean_squared_error: 0.2426 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2196\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0516 - root_mean_squared_error: 0.2271 - val_loss: 0.0453 - val_root_mean_squared_error: 0.2129\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0507 - root_mean_squared_error: 0.2253 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2141\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0495 - root_mean_squared_error: 0.2224 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0503 - root_mean_squared_error: 0.2244 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2078\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0485 - root_mean_squared_error: 0.2201 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0494 - root_mean_squared_error: 0.2222 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2075\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0481 - root_mean_squared_error: 0.2192 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2087\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0475 - root_mean_squared_error: 0.2179 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2111\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0465 - root_mean_squared_error: 0.2157 - val_loss: 0.0497 - val_root_mean_squared_error: 0.2229\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2260 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2110\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0484 - root_mean_squared_error: 0.2201 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2064\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0461 - root_mean_squared_error: 0.2147 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0462 - root_mean_squared_error: 0.2151 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2116\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2068\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0459 - root_mean_squared_error: 0.2144 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0486 - root_mean_squared_error: 0.2205 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2048\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0476 - root_mean_squared_error: 0.2181 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049\n",
            "Epoch 26/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0486 - root_mean_squared_error: 0.2204 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2057\n",
            "Epoch 27/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0468 - root_mean_squared_error: 0.2162 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2078\n",
            "Epoch 28/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0491 - root_mean_squared_error: 0.2216 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2048\n",
            "Epoch 29/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0465 - root_mean_squared_error: 0.2156 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2118\n",
            "Epoch 30/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0475 - root_mean_squared_error: 0.2179 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2079\n",
            "Epoch 31/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0510 - root_mean_squared_error: 0.2258 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2067\n",
            "Epoch 32/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0481 - root_mean_squared_error: 0.2193 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2070\n",
            "Epoch 33/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0531 - root_mean_squared_error: 0.2304 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2073\n",
            "Epoch 34/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0482 - root_mean_squared_error: 0.2196 - val_loss: 0.0534 - val_root_mean_squared_error: 0.2311\n",
            "Epoch 35/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0482 - root_mean_squared_error: 0.2196 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2068\n",
            "Epoch 36/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0470 - root_mean_squared_error: 0.2169 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2186\n",
            "Epoch 37/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0461 - root_mean_squared_error: 0.2146 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2110\n",
            "Epoch 38/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0478 - root_mean_squared_error: 0.2186 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105\n",
            "Epoch 39/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0478 - root_mean_squared_error: 0.2187 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2206\n",
            "Epoch 40/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0487 - root_mean_squared_error: 0.2206 - val_loss: 0.0554 - val_root_mean_squared_error: 0.2354\n",
            "Epoch 41/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0483 - root_mean_squared_error: 0.2197 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2060\n",
            "Epoch 42/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0476 - root_mean_squared_error: 0.2183 - val_loss: 0.0723 - val_root_mean_squared_error: 0.2689\n",
            "Epoch 43/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0483 - root_mean_squared_error: 0.2198 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2077\n",
            "Epoch 44/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0488 - root_mean_squared_error: 0.2210 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2143\n",
            "Epoch 45/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0487 - root_mean_squared_error: 0.2206 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377\n",
            "Epoch 46/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0485 - root_mean_squared_error: 0.2203 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2215\n",
            "Epoch 47/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0471 - root_mean_squared_error: 0.2170 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
            "Epoch 48/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0495 - root_mean_squared_error: 0.2225 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2101\n",
            "Epoch 49/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0528 - root_mean_squared_error: 0.2299 - val_loss: 0.0456 - val_root_mean_squared_error: 0.2136\n",
            "Epoch 50/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0487 - root_mean_squared_error: 0.2206 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
            "Epoch 51/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0501 - root_mean_squared_error: 0.2239 - val_loss: 0.0698 - val_root_mean_squared_error: 0.2641\n",
            "Epoch 52/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0479 - root_mean_squared_error: 0.2189 - val_loss: 0.0632 - val_root_mean_squared_error: 0.2513\n",
            "Epoch 53/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0513 - root_mean_squared_error: 0.2265 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2327\n",
            "Epoch 54/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0491 - root_mean_squared_error: 0.2216 - val_loss: 0.0512 - val_root_mean_squared_error: 0.2264\n",
            "Epoch 55/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0492 - root_mean_squared_error: 0.2218 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2206\n",
            "Epoch 56/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0509 - root_mean_squared_error: 0.2257 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2184\n",
            "Epoch 57/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0477 - root_mean_squared_error: 0.2184 - val_loss: 0.0550 - val_root_mean_squared_error: 0.2345\n",
            "Epoch 58/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0482 - root_mean_squared_error: 0.2196 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2058\n",
            "Epoch 59/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0480 - root_mean_squared_error: 0.2190 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2098\n",
            "Epoch 60/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0488 - root_mean_squared_error: 0.2209 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049\n",
            "Epoch 61/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0506 - root_mean_squared_error: 0.2249 - val_loss: 0.0463 - val_root_mean_squared_error: 0.2152\n",
            "Epoch 62/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0489 - root_mean_squared_error: 0.2211 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2109\n",
            "Epoch 63/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0539 - root_mean_squared_error: 0.2321 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2241\n",
            "Epoch 64/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0491 - root_mean_squared_error: 0.2217 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081\n",
            "Epoch 65/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0493 - root_mean_squared_error: 0.2221 - val_loss: 0.0557 - val_root_mean_squared_error: 0.2360\n",
            "Epoch 66/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0541 - root_mean_squared_error: 0.2325 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2140\n",
            "Epoch 67/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0494 - root_mean_squared_error: 0.2223 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043\n",
            "Epoch 68/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0491 - root_mean_squared_error: 0.2216 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2121\n",
            "Epoch 69/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0484 - root_mean_squared_error: 0.2200 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092\n",
            "Epoch 70/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0478 - root_mean_squared_error: 0.2186 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2046\n",
            "Epoch 71/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0512 - root_mean_squared_error: 0.2263 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2063\n",
            "Epoch 72/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2103\n",
            "Epoch 73/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0516 - root_mean_squared_error: 0.2272 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084\n",
            "Epoch 74/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0507 - root_mean_squared_error: 0.2251 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2184\n",
            "Epoch 75/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0496 - root_mean_squared_error: 0.2226 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2086\n",
            "Epoch 76/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0546 - root_mean_squared_error: 0.2337 - val_loss: 0.0800 - val_root_mean_squared_error: 0.2829\n",
            "Epoch 77/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0503 - root_mean_squared_error: 0.2242 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2227\n",
            "Epoch 78/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0493 - root_mean_squared_error: 0.2220 - val_loss: 0.0475 - val_root_mean_squared_error: 0.2181\n",
            "Epoch 79/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0489 - root_mean_squared_error: 0.2211 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163\n",
            "Epoch 80/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0535 - root_mean_squared_error: 0.2313 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2140\n",
            "Epoch 81/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0488 - root_mean_squared_error: 0.2208 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052\n",
            "Epoch 82/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0515 - root_mean_squared_error: 0.2270 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093\n",
            "Epoch 83/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0478 - root_mean_squared_error: 0.2187 - val_loss: 0.0698 - val_root_mean_squared_error: 0.2642\n",
            "Epoch 84/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 0.0518 - root_mean_squared_error: 0.2276 - val_loss: 0.0506 - val_root_mean_squared_error: 0.2248\n",
            "Epoch 85/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0468 - root_mean_squared_error: 0.2163 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2266\n",
            "Epoch 86/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0531 - root_mean_squared_error: 0.2303 - val_loss: 0.0496 - val_root_mean_squared_error: 0.2227\n",
            "Epoch 87/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0522 - root_mean_squared_error: 0.2285 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2327\n",
            "Epoch 88/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0481 - root_mean_squared_error: 0.2193 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2216\n",
            "Epoch 89/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0497 - root_mean_squared_error: 0.2229 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2051\n",
            "Epoch 90/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0481 - root_mean_squared_error: 0.2193 - val_loss: 0.0481 - val_root_mean_squared_error: 0.2192\n",
            "Epoch 91/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0473 - root_mean_squared_error: 0.2176 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2113\n",
            "Epoch 92/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0500 - root_mean_squared_error: 0.2236 - val_loss: 0.0490 - val_root_mean_squared_error: 0.2213\n",
            "Epoch 93/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0477 - root_mean_squared_error: 0.2184 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2058\n",
            "Epoch 94/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0530 - root_mean_squared_error: 0.2301 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
            "Epoch 95/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0531 - root_mean_squared_error: 0.2305 - val_loss: 0.0557 - val_root_mean_squared_error: 0.2360\n",
            "Epoch 96/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0503 - root_mean_squared_error: 0.2244 - val_loss: 0.0444 - val_root_mean_squared_error: 0.2108\n",
            "Epoch 97/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0490 - root_mean_squared_error: 0.2214 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043\n",
            "Epoch 98/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0513 - root_mean_squared_error: 0.2265 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2162\n",
            "Epoch 99/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0513 - root_mean_squared_error: 0.2265 - val_loss: 0.0639 - val_root_mean_squared_error: 0.2527\n",
            "Epoch 100/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0515 - root_mean_squared_error: 0.2269 - val_loss: 0.0619 - val_root_mean_squared_error: 0.2487\n",
            "10/10 - 0s - loss: 0.0682 - root_mean_squared_error: 0.2612 - 46ms/epoch - 5ms/step\n",
            "Test RMSE: 0.261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 6"
      ],
      "metadata": {
        "id": "Uiz5ka7cPQ9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(-1, 784).astype(np.float32) / 255.0\n",
        "X_test = X_test.reshape(-1, 784).astype(np.float32) / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no7hr7JWPPMB",
        "outputId": "17850459-eaad-4970-f884-6f0799af4e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 12s 7ms/step - loss: 0.2690 - accuracy: 0.9229 - val_loss: 0.1297 - val_accuracy: 0.9600\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1119 - accuracy: 0.9671 - val_loss: 0.0982 - val_accuracy: 0.9694\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0782 - accuracy: 0.9763 - val_loss: 0.1116 - val_accuracy: 0.9666\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0847 - val_accuracy: 0.9754\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0816 - val_accuracy: 0.9753\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0369 - accuracy: 0.9881 - val_loss: 0.0853 - val_accuracy: 0.9759\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.0911 - val_accuracy: 0.9744\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.0984 - val_accuracy: 0.9760\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.0971 - val_accuracy: 0.9763\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.1026 - val_accuracy: 0.9765\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.1002 - val_accuracy: 0.9760\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.1011 - val_accuracy: 0.9763\n",
            "Epoch 13/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.1091 - val_accuracy: 0.9777\n",
            "Epoch 14/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.1040 - val_accuracy: 0.9788\n",
            "Epoch 15/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.1101 - val_accuracy: 0.9785\n",
            "Epoch 16/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1297 - val_accuracy: 0.9751\n",
            "Epoch 17/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.1422 - val_accuracy: 0.9712\n",
            "Epoch 18/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.1662 - val_accuracy: 0.9726\n",
            "Epoch 19/20\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.1117 - val_accuracy: 0.9804\n",
            "Epoch 20/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1402 - val_accuracy: 0.9784\n",
            "313/313 - 1s - loss: 0.1438 - accuracy: 0.9749 - 576ms/epoch - 2ms/step\n",
            "Test accuracy: 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Advance Task"
      ],
      "metadata": {
        "id": "yzWj_ojPUmbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 1"
      ],
      "metadata": {
        "id": "DObdUnXlUsah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Iris.csv')\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
        "\n",
        "y = df[\"Species\"].apply(lambda x: 0 if x == \"Iris-versicolor\" else 1).values\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
        "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)\n",
        "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "model = BinaryClassifier()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train.unsqueeze(1).float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val)\n",
        "        val_loss = criterion(val_outputs, y_val.unsqueeze(1).float())\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_preds = (test_outputs > 0.5).float()\n",
        "    test_accuracy = (test_preds.squeeze() == y_test).float().mean()\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL_8YOfRUrGI",
        "outputId": "5412fcb8-0adc-4fcb-8da9-73a06e349bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.7410, Val Loss: 0.8223\n",
            "Epoch [20/100], Loss: 0.6809, Val Loss: 0.7332\n",
            "Epoch [30/100], Loss: 0.6279, Val Loss: 0.6552\n",
            "Epoch [40/100], Loss: 0.5815, Val Loss: 0.5870\n",
            "Epoch [50/100], Loss: 0.5404, Val Loss: 0.5275\n",
            "Epoch [60/100], Loss: 0.5040, Val Loss: 0.4758\n",
            "Epoch [70/100], Loss: 0.4715, Val Loss: 0.4307\n",
            "Epoch [80/100], Loss: 0.4421, Val Loss: 0.3916\n",
            "Epoch [90/100], Loss: 0.4152, Val Loss: 0.3568\n",
            "Epoch [100/100], Loss: 0.3903, Val Loss: 0.3260\n",
            "Test Accuracy: 0.8500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 2"
      ],
      "metadata": {
        "id": "ht6CQxtXY1Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Iris.csv')\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]].values\n",
        "\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "y = enc.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiClassClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 50)\n",
        "        self.fc2 = nn.Linear(50, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MultiClassClassifier()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train.argmax(dim=1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val)\n",
        "        val_loss = criterion(val_outputs, y_val.argmax(dim=1))\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_preds = torch.argmax(test_outputs, dim=1)\n",
        "    test_accuracy = (test_preds == y_test.argmax(dim=1)).float().mean()\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC4YQMRlYtNQ",
        "outputId": "bc38e95e-3026-4f7b-ed50-dc29a2f841f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.9712, Val Loss: 0.9342\n",
            "Epoch [20/100], Loss: 0.8722, Val Loss: 0.8512\n",
            "Epoch [30/100], Loss: 0.7836, Val Loss: 0.7780\n",
            "Epoch [40/100], Loss: 0.7045, Val Loss: 0.7129\n",
            "Epoch [50/100], Loss: 0.6343, Val Loss: 0.6555\n",
            "Epoch [60/100], Loss: 0.5724, Val Loss: 0.6054\n",
            "Epoch [70/100], Loss: 0.5182, Val Loss: 0.5615\n",
            "Epoch [80/100], Loss: 0.4710, Val Loss: 0.5230\n",
            "Epoch [90/100], Loss: 0.4299, Val Loss: 0.4893\n",
            "Epoch [100/100], Loss: 0.3938, Val Loss: 0.4605\n",
            "Test Accuracy: 0.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 3"
      ],
      "metadata": {
        "id": "lafbabF6ZI53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "y = df[\"SalePrice\"]\n",
        "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]].values\n",
        "\n",
        "y = np.log(y.values)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
        "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = RegressionModel()\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val)\n",
        "        val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNeUeeXSY_PS",
        "outputId": "1ef60df2-d8d6-414a-c401-fbc28bd62d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 141.3555, Val Loss: 140.5435\n",
            "Epoch [20/100], Loss: 137.7226, Val Loss: 136.9642\n",
            "Epoch [30/100], Loss: 134.1373, Val Loss: 133.4254\n",
            "Epoch [40/100], Loss: 130.5511, Val Loss: 129.8783\n",
            "Epoch [50/100], Loss: 126.9177, Val Loss: 126.2774\n",
            "Epoch [60/100], Loss: 123.1976, Val Loss: 122.5844\n",
            "Epoch [70/100], Loss: 119.3626, Val Loss: 118.7684\n",
            "Epoch [80/100], Loss: 115.3908, Val Loss: 114.8068\n",
            "Epoch [90/100], Loss: 111.2665, Val Loss: 110.6890\n",
            "Epoch [100/100], Loss: 106.9805, Val Loss: 106.4039\n",
            "Test Loss: 106.7589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 4"
      ],
      "metadata": {
        "id": "YmciqERVZh0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_dataset, [48000, 12000])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MNISTClassifier()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = correct / len(val_loader.dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        test_loss += criterion(outputs, labels).item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_accuracy = correct / len(test_loader.dataset)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "44SkoDTAZfmt",
        "outputId": "6d22d23d-4041-44e4-9bf7-4cee6bdd9b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 6010050.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 160965.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1510170.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2314485.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch [1/20], Val Loss: 0.0074, Val Accuracy: 0.9286\n",
            "Epoch [2/20], Val Loss: 0.0056, Val Accuracy: 0.9456\n",
            "Epoch [3/20], Val Loss: 0.0043, Val Accuracy: 0.9594\n",
            "Epoch [4/20], Val Loss: 0.0040, Val Accuracy: 0.9614\n",
            "Epoch [5/20], Val Loss: 0.0042, Val Accuracy: 0.9591\n",
            "Epoch [6/20], Val Loss: 0.0033, Val Accuracy: 0.9679\n",
            "Epoch [7/20], Val Loss: 0.0032, Val Accuracy: 0.9684\n",
            "Epoch [8/20], Val Loss: 0.0034, Val Accuracy: 0.9673\n",
            "Epoch [9/20], Val Loss: 0.0032, Val Accuracy: 0.9708\n",
            "Epoch [10/20], Val Loss: 0.0038, Val Accuracy: 0.9663\n",
            "Epoch [11/20], Val Loss: 0.0036, Val Accuracy: 0.9692\n",
            "Epoch [12/20], Val Loss: 0.0033, Val Accuracy: 0.9728\n",
            "Epoch [13/20], Val Loss: 0.0039, Val Accuracy: 0.9653\n",
            "Epoch [14/20], Val Loss: 0.0034, Val Accuracy: 0.9694\n",
            "Epoch [15/20], Val Loss: 0.0035, Val Accuracy: 0.9718\n",
            "Epoch [16/20], Val Loss: 0.0041, Val Accuracy: 0.9663\n",
            "Epoch [17/20], Val Loss: 0.0034, Val Accuracy: 0.9725\n",
            "Epoch [18/20], Val Loss: 0.0035, Val Accuracy: 0.9707\n",
            "Epoch [19/20], Val Loss: 0.0040, Val Accuracy: 0.9705\n",
            "Epoch [20/20], Val Loss: 0.0039, Val Accuracy: 0.9687\n",
            "Test Loss: 0.0044, Test Accuracy: 0.9667\n"
          ]
        }
      ]
    }
  ]
}